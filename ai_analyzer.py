# ai_analyzer.py - å›ºå®šå•é¡Œç‰ˆæœ¬

import io
import base64
from PIL import Image
import requests


class ImageProcessor:
    """åœ–ç‰‡é è™•ç†å™¨ï¼ˆä¸è®Šï¼‰"""
    
    def __init__(self, max_side: int = 1280, quality: int = 72):
        self.max_side = max_side
        self.quality = quality
    
    def resize_and_encode(self, pil_img: Image.Image) -> str:
        """èª¿æ•´å¤§å°ä¸¦ç·¨ç¢¼ç‚º base64"""
        w, h = pil_img.size
        
        if max(w, h) > self.max_side:
            ratio = self.max_side / max(w, h)
            nw, nh = int(w * ratio), int(h * ratio)
            pil_img = pil_img.resize((nw, nh), Image.Resampling.LANCZOS)
        
        if pil_img.mode in ('RGBA', 'LA', 'P'):
            bg = Image.new('RGB', pil_img.size, (255, 255, 255))
            if pil_img.mode == 'P':
                pil_img = pil_img.convert('RGBA')
            bg.paste(pil_img, mask=pil_img.split()[-1] if pil_img.mode in ('RGBA', 'LA') else None)
            pil_img = bg
        
        buf = io.BytesIO()
        pil_img.save(buf, format='JPEG', quality=self.quality)
        buf.seek(0)
        return base64.b64encode(buf.read()).decode('utf-8')


class PromptBuilder:
    """Prompt æ§‹å»ºå™¨ - å›ºå®šå•é¡Œ"""
    
    # å›ºå®šçš„å•é¡Œï¼ˆå¯ä»¥åœ¨é€™è£¡ä¿®æ”¹ï¼‰
    DEFAULT_QUESTION = "è«‹åˆ†æé€™å€‹ Instagram å¸³è™Ÿçš„å•†æ¥­åƒ¹å€¼å’Œå½±éŸ¿åŠ›ï¼ŒåŒ…æ‹¬å…§å®¹å“è³ªã€ç²‰çµ²äº’å‹•ã€å“ç‰Œæ½›åŠ›ç­‰é¢å‘ï¼Œä¸¦æä¾›å…·é«”çš„è©•ä¼°æŒ‡æ¨™å’Œå»ºè­°ã€‚"
    
    @staticmethod
    def build_analysis_prompt(question: str = None) -> str:
        """
        å»ºæ§‹åˆ†æ prompt
        
        Args:
            question: è‡ªå®šç¾©å•é¡Œï¼ˆå¦‚æœç‚º Noneï¼Œä½¿ç”¨é è¨­å•é¡Œï¼‰
        
        Returns:
            å®Œæ•´çš„ prompt
        """
        final_question = question or PromptBuilder.DEFAULT_QUESTION
        
        return f"""è«‹æ ¹æ“šé€™å€‹ Instagram æˆªåœ–å›ç­”ä»¥ä¸‹å•é¡Œï¼š

{final_question}

è«‹è©³ç´°èªªæ˜ä½ çš„åˆ†æé‚è¼¯å’Œè¨ˆç®—éç¨‹ï¼Œæä¾›æ¸…æ™°çš„æ¨ç†æ­¥é©Ÿã€‚
è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œæ‰€æœ‰åƒ¹æ ¼ä»¥æ–°å°å¹£ (NT$) è¨ˆç®—ã€‚"""


class ResponseCleaner:
    """å›æ‡‰æ¸…ç†å™¨"""
    
    @staticmethod
    def clean_response(raw_response: str) -> str:
        """æ¸…ç† AI å›æ‡‰"""
        cleaned = raw_response.strip()
        
        # ç§»é™¤ markdown code block
        if cleaned.startswith("```") and cleaned.endswith("```"):
            lines = cleaned.split("\n")
            if len(lines) > 2:
                cleaned = "\n".join(lines[1:-1]).strip()
        
        cleaned = cleaned.replace("```markdown", "").replace("```", "")
        
        return cleaned.strip()


class DataExtractor:
    """å¾ AI å›æ‡‰ä¸­æå–çµæ§‹åŒ–æ•¸æ“š"""
    
    @staticmethod
    def extract_metrics(analysis_text: str) -> dict:
        """
        å¾åˆ†ææ–‡æœ¬ä¸­æå–å•†æ¥­æŒ‡æ¨™
        
        Args:
            analysis_text: AI çš„åˆ†æå›æ‡‰æ–‡æœ¬
            
        Returns:
            åŒ…å«æå–çš„æŒ‡æ¨™çš„å­—å…¸
        """
        import re
        
        metrics = {
            "followers": None,
            "engagement_rate": None,
            "engagement_percentage": None,
            "likes": [],
            "content_quality": None,
            "brand_potential": None,
            "income_potential": {
                "min_per_post": None,
                "max_per_post": None,
                "avg_per_post": None,
                "monthly_posts": None,
                "monthly_income": None
            },
            "recommendations": [],
            "raw_text": analysis_text
        }
        
        # æå–ç²‰çµ²æ•¸
        followers_match = re.search(r'(\d+(?:,\d+)*(?:\.\d+)?)\s*K', analysis_text)
        if followers_match:
            followers_str = followers_match.group(1).replace(',', '')
            try:
                followers_val = float(followers_str)
                metrics["followers"] = int(followers_val * 1000) if 'K' in analysis_text[followers_match.start():followers_match.end()] else int(followers_val)
            except:
                pass
        
        # æå–äº’å‹•ç‡ï¼ˆæ›´å¤šçš„è®Šé«”ï¼‰
        engagement_match = re.search(r'äº’å‹•ç‡[ï¼š:]\s*([0-9.]+)%', analysis_text)
        if not engagement_match:
            engagement_match = re.search(r'äº’å‹•ç‡ç´„ç‚º\s*([0-9.]+)%', analysis_text)
        if not engagement_match:
            engagement_match = re.search(r'([0-9.]+)%[ï¼Œ,]?\s*(?:çš„)?äº’å‹•ç‡', analysis_text)
        
        if engagement_match:
            try:
                metrics["engagement_percentage"] = float(engagement_match.group(1))
                metrics["engagement_rate"] = float(engagement_match.group(1)) / 100
            except:
                pass
        
        # æå–é»è®šæ•¸ï¼ˆæ›´å¤šçš„è®Šé«”ï¼‰
        likes_matches = re.findall(r'(\d+(?:,\d+)*)\s*(?:é»è®š|ğŸ‘|likes)', analysis_text)
        for like in likes_matches[:5]:  # æœ€å¤šæå– 5 å€‹
            try:
                metrics["likes"].append(int(like.replace(',', '')))
            except:
                pass
        
        # å¦‚æœæ‰¾ä¸åˆ°é»è®šæ•¸ï¼Œå˜—è©¦æ‰¾åˆ°æ•¸å­—å¾Œè·Ÿ"ã€"çš„æ¨¡å¼
        if not metrics["likes"]:
            likes_matches = re.findall(r'é»è®šæ•¸ç‚º\s*([0-9,]+)(?:ã€|ï¼Œ)', analysis_text)
            for like in likes_matches[:5]:
                try:
                    metrics["likes"].append(int(like.replace(',', '')))
                except:
                    pass
        
        # æå–å…§å®¹å“è³ªè©•ä¼°
        quality_match = re.search(r'ç…§ç‰‡å“è³ª[ï¼š:]\s*([^ã€‚\n]+)', analysis_text)
        if quality_match:
            metrics["content_quality"] = quality_match.group(1).strip()
        
        # æå–å“ç‰Œæ½›åŠ›
        brand_match = re.search(r'(?:å“ç‰Œæ½›åŠ›|æ½›åœ¨åˆä½œæ©Ÿæœƒ)[ï¼š:]\s*([^ã€‚\n]+)', analysis_text)
        if brand_match:
            metrics["brand_potential"] = brand_match.group(1).strip()
        
        # æå–æ”¶å…¥æ½›åŠ›
        income_min_match = re.search(r'NT\$(\d+(?:,\d+)*)\s*è‡³\s*NT\$(\d+(?:,\d+)*)', analysis_text)
        if income_min_match:
            try:
                metrics["income_potential"]["min_per_post"] = int(income_min_match.group(1).replace(',', ''))
                metrics["income_potential"]["max_per_post"] = int(income_min_match.group(2).replace(',', ''))
                metrics["income_potential"]["avg_per_post"] = (
                    metrics["income_potential"]["min_per_post"] + 
                    metrics["income_potential"]["max_per_post"]
                ) // 2
            except:
                pass
        
        # æå–å¹³å‡åˆä½œè²»ç”¨å’Œæœˆæ”¶å…¥
        avg_income_match = re.search(r'å¹³å‡æ¯ç¯‡åˆä½œè²»ç”¨ç‚º\s*NT\$(\d+(?:,\d+)*)', analysis_text)
        if avg_income_match:
            try:
                metrics["income_potential"]["avg_per_post"] = int(avg_income_match.group(1).replace(',', ''))
            except:
                pass
        
        monthly_income_match = re.search(r'æœˆæ”¶å…¥ç´„ç‚º\s*NT\$(\d+(?:,\d+)*)', analysis_text)
        if monthly_income_match:
            try:
                metrics["income_potential"]["monthly_income"] = int(monthly_income_match.group(1).replace(',', ''))
            except:
                pass
        
        # æå–å»ºè­°ï¼ˆæ”¹é€²çš„æ¨¡å¼ï¼‰
        suggestions_section = re.search(r'(?:###\s*)?(?:å»ºè­°|æ¨è–¦)[ï¼š:]?(.*?)(?:$|é€™äº›è©•ä¼°|---)', analysis_text, re.DOTALL)
        if suggestions_section:
            suggestions_text = suggestions_section.group(1)
            # é¦–å…ˆå˜—è©¦æ‰¾åˆ°å¸¶æœ‰ç·¨è™Ÿã€æ¨™é¡Œå’Œæè¿°çš„é …ç›®
            suggestions = re.findall(r'[0-9]+\.\s*\*?\*?([^ï¼š:ã€‚\n]+)\*?\*?[ï¼š:]\s*([^ã€‚\n]+)', suggestions_text)
            if suggestions:
                metrics["recommendations"] = [
                    f"{title.strip().replace('**', '')}: {desc.strip()}" 
                    for title, desc in suggestions
                ]
            else:
                # å¦‚æœæ²’æ‰¾åˆ°å®Œæ•´çš„æ¨™é¡Œ:æè¿°ï¼Œå˜—è©¦åªæ‰¾é …ç›®æ¨™é¡Œ
                suggestions = re.findall(r'[0-9]+\.\s*\*?\*?([^ã€‚\nï¼š]+)', suggestions_text)
                if suggestions:
                    metrics["recommendations"] = [
                        s.strip().replace('**', '') 
                        for s in suggestions if s.strip()
                    ]
                else:
                    # æœ€å¾Œçš„å˜—è©¦ï¼šæ‰¾æ‰€æœ‰ä»¥æ•¸å­—å’Œå¥è™Ÿé–‹é ­çš„è¡Œ
                    suggestions = re.findall(r'^\s*[0-9]+\.\s*(.+?)$', suggestions_text, re.MULTILINE)
                    metrics["recommendations"] = [
                        s.strip().replace('**', '') 
                        for s in suggestions if s.strip()
                    ]
        
        return metrics


class OpenAIAnalyzer:
    """OpenAI åˆ†æå™¨"""
    
    def __init__(self, api_key: str, model: str = "gpt-4o"):
        self.api_key = api_key
        self.model = model
        self.api_url = "https://api.openai.com/v1/chat/completions"
    
    def analyze_image(
        self, 
        image_base64: str, 
        question: str,
        max_tokens: int = 1500,
        temperature: float = 0.7
    ) -> str:
        """
        ä½¿ç”¨ OpenAI Vision API åˆ†æåœ–ç‰‡
        
        Args:
            image_base64: base64 ç·¨ç¢¼çš„åœ–ç‰‡
            question: å•é¡Œ
            max_tokens: æœ€å¤§ token æ•¸
            temperature: æº«åº¦åƒæ•¸
            
        Returns:
            AI çš„ç´”æ–‡å­—å›ç­”
        """
        if not self.api_key:
            raise ValueError("OpenAI API key æœªè¨­ç½®")
        
        prompt = PromptBuilder.build_analysis_prompt(question)
        
        content = [
            {"type": "text", "text": prompt},
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{image_base64}"
                }
            }
        ]
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": content}],
            "max_tokens": max_tokens,
            "temperature": temperature
        }
        
        print(f"[OpenAI] èª¿ç”¨ API: {self.model}")
        print(f"[OpenAI] å•é¡Œ: {question[:50]}...")
        
        response = requests.post(
            self.api_url, 
            headers=headers, 
            json=payload, 
            timeout=90
        )
        response.raise_for_status()
        
        data = response.json()
        raw_text = data["choices"][0]["message"]["content"]
        
        print(f"[OpenAI] âœ… å›æ‡‰é•·åº¦: {len(raw_text)}")
        
        return raw_text


class IGAnalyzer:
    """IG å¸³è™Ÿåˆ†æå™¨ - ä¸»å…¥å£"""
    
    def __init__(
        self, 
        api_key: str, 
        model: str = "gpt-4o",
        max_side: int = 1280,
        quality: int = 72
    ):
        self.image_processor = ImageProcessor(max_side, quality)
        self.openai = OpenAIAnalyzer(api_key, model)
        self.cleaner = ResponseCleaner()
    
    def analyze_profile(self, profile_image: Image.Image) -> str:
        """
        åˆ†æ IG æˆªåœ–ï¼ˆä½¿ç”¨é è¨­å•é¡Œï¼‰
        
        Args:
            profile_image: IG å€‹äººé æˆªåœ–
            
        Returns:
            AI çš„å›ç­”ï¼ˆç´”æ–‡å­—ï¼‰
        """
        print("[IGAnalyzer] é–‹å§‹åˆ†ææµç¨‹")
        
        # 1. è™•ç†åœ–ç‰‡
        print("[IGAnalyzer] Step 1: è™•ç†åœ–ç‰‡")
        image_base64 = self.image_processor.resize_and_encode(profile_image)
        
        # 2. ä½¿ç”¨å›ºå®šå•é¡Œèª¿ç”¨ OpenAI
        print("[IGAnalyzer] Step 2: èª¿ç”¨ OpenAI APIï¼ˆä½¿ç”¨å›ºå®šå•é¡Œï¼‰")
        raw_answer = self.openai.analyze_image(
            image_base64, 
            PromptBuilder.DEFAULT_QUESTION
        )
        
        # 3. æ¸…ç†å›æ‡‰
        print("[IGAnalyzer] Step 3: æ¸…ç†å›æ‡‰")
        clean_answer = self.cleaner.clean_response(raw_answer)
        
        print("[IGAnalyzer] âœ… åˆ†æå®Œæˆ")
        return clean_answer